
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":["admin"],"categories":null,"content":"I am an Assistant Professor of Computer Science at Virginia Tech. My research interests span the areas of compilers, programming languages, and high-performance computing. I am particularly interested in solving challenges arise from the irregularity in programs.\nI am currently looking for motivated PhD students starting in Fall 2025. Please feel free to reach out if my work interests you.\nI received my PhD from Purdue University where I was fortunate enough to advised by Milind Kulkarni. I was part of the PurPL group at Purdue University. I earned my Bachelor’s in Electronic and Telecommunication Engineering from UoM, Sri Lanka.\n[Research Statement] [Teaching Statement]\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://kirshanthans.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am an Assistant Professor of Computer Science at Virginia Tech. My research interests span the areas of compilers, programming languages, and high-performance computing. I am particularly interested in solving challenges arise from the irregularity in programs.","tags":null,"title":"","type":"authors"},{"authors":["Adhitha Dias","Logan Anderson","Kirshanthan Sundararajah","Artem Pelenitsyn","Milind Kulkarni"],"categories":null,"content":"","date":1728345600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728345600,"objectID":"1deb5b37b8ac8b3d1c68275a52709de7","permalink":"https://kirshanthans.github.io/publication/2024oopsla/","publishdate":"2024-10-08T00:00:00Z","relpermalink":"/publication/2024oopsla/","section":"publication","summary":"Automated code generation and performance enhancements for sparse tensor algebra have become essential in many real-world applications, such as quantum computing, physical simulations, computational chemistry, and machine learning. General sparse tensor algebra compilers are not always versatile enough to generate asymptotically optimal code for sparse tensor contractions. This paper shows how to generate asymptotically better schedules for complex sparse tensor expressions using kernel fission and fusion. We present generalized loop restructuring transformations to reduce asymptotic time complexity and memory footprint. Furthermore, we present an auto-scheduler that uses a partially ordered set (poset)-based cost model that uses both time and auxiliary memory complexities to prune the search space of schedules. In addition, we highlight the use of Satisfiability Module Theory (SMT) solvers in sparse auto-schedulers to approximate the Pareto frontier of better schedules to the smallest number of possible schedules, with user-defined constraints available at compile-time. Finally, we show that our auto-scheduler can select better-performing schedules and generate code for them. Our results show that the auto-scheduler provided schedules achieve orders-of-magnitude speedup compared to the code generated by the Tensor Algebra Compiler (TACO) for several computations on different real-world tensors.","tags":[],"title":"SparseAuto: An Auto-scheduler for Sparse Tensor Computations using Recursive Loop Nest Restructuring","type":"publication"},{"authors":["Vidush Singhal","Laith Sakka","Kirshanthan Sundararajah","Ryan R Newton","Milind Kulkarni"],"categories":null,"content":"","date":1716249600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1716249600,"objectID":"db2ea93cba6e8c72161fbcda8dd4f981","permalink":"https://kirshanthans.github.io/publication/2024taco/","publishdate":"2024-05-21T00:00:00Z","relpermalink":"/publication/2024taco/","section":"publication","summary":"Many applications are designed to perform traversals on tree-like data structures. Fusing and parallelizing these traversals enhance the performance of applications. Fusing multiple traversals improves the locality of the application. The runtime of an application can be significantly reduced by extracting parallelism and utilizing multi-threading. Prior frameworks have tried to fuse and parallelize tree traversals using coarse-grained approaches, leading to missed fine-grained opportunities for improving performance. Other frameworks have successfully supported fine-grained fusion on heterogeneous tree types but fall short regarding parallelization. We introduce a new framework Orchard built on top of Grafter. Orchard’s novelty lies in allowing the programmer to transform tree traversal applications by automatically applying fine-grained fusion and extracting heterogeneous parallelism. Orchard allows the programmer to write general tree traversal applications in a simple and elegant embedded Domain-Specific Language (eDSL). We show that the combination of fine-grained fusion and heterogeneous parallelism performs better than each alone when the conditions are met.","tags":[],"title":"Orchard: Heterogeneous Parallelism and Fine-grained Fusion for Complex Tree Traversals","type":"publication"},{"authors":["Pratyush Das","Adhitha Dias","Anxhelo Xhebraj","Artem Pelenitsyn","Kirshanthan Sundararajah","Milind Kulkarni"],"categories":null,"content":"","date":1712102400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712102400,"objectID":"660ad8f8b37f70a99342d4f9aa343569","permalink":"https://kirshanthans.github.io/publication/2024arxiva/","publishdate":"2024-04-03T00:00:00Z","relpermalink":"/publication/2024arxiva/","section":"publication","summary":"Sparse Matrices found in the real world often have some structure in how the dense elements are organized. While the inspector-executor model inspects matrices for structure, its generality can overlook further specialization. We propose a system that - if the sparse matrix is stored in a blocked storage format - can generate more efficient code by constructing regular loops over these blocks. Our system performs a specified computation over every element of the block instead of avoiding computing any sparse element at all and achieving regularity in specialized code. The system is extensible, providing a dense block iterator for the user to express any computation over these dense blocks. We show that this approach can significantly speed up SpMV and SpMM operations over the state-of-the-art systems Partially-Strided Codelets and Sparse Register Tiling.","tags":[],"title":"SABLE: Staging Blocked Evaluation of Sparse Matrix Computations","type":"publication"},{"authors":["Charitha Saumya","Rohan Gangaraju","Kirshanthan Sundararajah","Milind Kulkarni"],"categories":null,"content":"","date":1690848000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690848000,"objectID":"2991f2c7f42955fa9c3d72b15cbe655d","permalink":"https://kirshanthans.github.io/publication/2023arxiv/","publishdate":"2023-08-01T00:00:00Z","relpermalink":"/publication/2023arxiv/","section":"publication","summary":"Dynamic symbolic execution (DSE) suffers from path explosion problem when the target program has many conditional branches. Classical approach for managing the path explosion problem is dynamic state merging. Dynamic state merging combines similar symbolic program states together to avoid the exponential growth of states in DSE. However, state merging still requires solver invocations at each branch point of the program even when both paths of the branch is feasible and, the best path search strategy for DSE may not create the best state merging opportunities. Some drawbacks of state merging can be mitigated by compile-time state merging i.e. branch elimination by converting control-flow into data-flow. In this paper, we propose a non-semantics preserving but failure-preserving compiler technique for removing expensive symbolic branches in a program to improve the scalability of DSE. We develop a framework for detecting spurious bugs that can be inserted by our transformation. Finally, we show that our transformation can significantly improve the performance of exhaustive DSE on variety of benchmarks and helps in achieving more coverage in a large real-world subjects within a limited time budget.","tags":[],"title":"Targeted Control-flow Transformations for Mitigating Path Explosion in Dynamic Symbolic Execution","type":"publication"},{"authors":["Rodrigo Rocha","Charitha Saumya","Kirshanthan Sundararajah","Pavlos Petoumenos","Milind Kulkarni","Michael F. P. O’Boyle"],"categories":null,"content":"","date":1676851200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676851200,"objectID":"95ec95e76ce06f9e92392be743b89b7a","permalink":"https://kirshanthans.github.io/publication/2023cc/","publishdate":"2023-02-20T00:00:00Z","relpermalink":"/publication/2023cc/","section":"publication","summary":"Binary code size is a first-class design consideration in many computing domains and a critical factor in many more, but compiler optimizations targeting code size are few and often limited in functionality. When size reduction opportunities are left unexploited, it results in higher downstream costs such as memory, storage, bandwidth, or programmer time. We present HyBF, a framework to manage code merging techniques that target conditional branches (i.e., if-then-else) with similar code regions on both paths. While such code can be easily and profitably merged and with little control flow overhead, existing techniques generally fail to fully handle it. Our work is inspired by branch fusion, a technique for merging similar code in if-then-else statements, which is aimed at reducing thread divergence in GPUs. We introduce two new branch fusion techniques that can be applied on almost any if-then-else statement and can uncover many more code merging opportunities. The two approaches are mostly orthogonal and have different limitations and strengths. We integrate them into a single framework, HyBF, which can choose the optimal approach on per branch basis to maximize the potential of reducing code size. Our results show that we can achieve significant code savings on top of already highly optimized binaries, including state-of-the-art code size optimizations. Over 61 benchmarks, we reduce code size on 43 of them. That reduction typically ranges from a few hundred to a few thousand bytes, but for specific benchmarks it can be substantial and as high as 4.2% or 67 KB.","tags":[],"title":"HyBF: A Hybrid Branch Fusion Strategy for Code Size Reduction","type":"publication"},{"authors":["Kirshanthan Sundararajah","Charitha Saumya","Milind Kulkarni"],"categories":null,"content":"","date":1667260800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667260800,"objectID":"ffb9ec4f16163f176cebf3fba6e7d895","permalink":"https://kirshanthans.github.io/publication/2022oopsla/","publishdate":"2022-11-01T00:00:00Z","relpermalink":"/publication/2022oopsla/","section":"publication","summary":"Scheduling transformations reorder operations in a program to improve locality and/or parallelism. There are mature loop transformation frameworks such as the polyhedral model for composing and applying instance-wise scheduling transformations for loop nests.In recent years, there have been efforts to build frameworks for composing and applying scheduling transformations for nested recursion and loops, but these frameworks cannot employ the full power of transformations for loop nests since they have overly-restrictive representations. This paper describes a new framework, UniRec, that not only generalizes prior frameworks for reasoning about transformations on recursion, but also generalizes the unimodular framework, and hence unifies reasoning about perfectly-nested loops and recursion.","tags":[],"title":"UniRec: A Unimodular-Like Framework for Nested Recursions and Loops","type":"publication"},{"authors":["Adhitha Dias","Kirshanthan Sundararajah","Charitha Saumya","Milind Kulkarni"],"categories":null,"content":"","date":1656374400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656374400,"objectID":"be5e9b198bde7967b89554323629c329","permalink":"https://kirshanthans.github.io/publication/2022ics/","publishdate":"2022-06-28T00:00:00Z","relpermalink":"/publication/2022ics/","section":"publication","summary":"Sparse tensor algebra computations have become important in many real-world applications like machine learning, scientific simulations, and data mining. Hence, automated code generation and performance optimizations for tensor algebra kernels are paramount. Recent advancements such as the Tensor Algebra Compiler (TACO) greatly generalize and automate the code generation for tensor algebra expressions. However, the code generated by TACO for many important tensor computations remains suboptimal due to the absence of a scheduling directive to support transformations such as distribution/fusion. This paper extends TACO's scheduling space to support kernel distribution/loop fusion in order to reduce asymptotic time complexity and improve locality of complex tensor algebra computations. We develop an intermediate representation (IR) for tensor operations called branched iteration graph which specifies breakdown of the computation into smaller ones (kernel distribution) and then fuse (loop fusion) outermost dimensions of the loop nests, while the inner-most dimensions are distributed, to increase data locality. We describe exchanges of intermediate results between space iteration spaces, transformation in the IR, and its programmatic invocation. Finally, we show that the transformation can be used to optimize sparse tensor kernels. Our results show that this new transformation significantly improves the performance of several real-world tensor algebra computations compared to TACO-generated code.","tags":[],"title":"SparseLNR: Accelerating Sparse Tensor Computations Using Loop Nest Restructuring","type":"publication"},{"authors":["Charitha Saumya","Kirshanthan Sundararajah","Milind Kulkarni"],"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"a0a86852342ab8e21ff9f07ca667128d","permalink":"https://kirshanthans.github.io/publication/2022cgo/","publishdate":"2022-01-01T00:00:00Z","relpermalink":"/publication/2022cgo/","section":"publication","summary":"GPGPUs use the Single-Instruction-Multiple-Thread (SIMT) execution model where a group of threads--wavefront or war--execute instructions in lockstep. When threads in a group encounter a branching instruction, not all threads in the group take the same path, a phenomenon known as control-flow divergence. The control-flow divergence causes performance degradation because both paths of the branch must be executed one after the other. Prior research has primarily addressed this issue through architectural modifications. We observe that certain GPGPU kernels with control-flow divergence have similar control-flow structures with similar instructions on both sides of a branch. This structure can be exploited to reduce control-flow divergence by melding the two sides of the branch allowing threads to reconverge early, reducing divergence. In this work, we present CFM, a compiler analysis and transformation framework that can meld divergent control-flow structures with similar instruction sequences. We show that CFM can reduce the performance degradation from control-flow divergence.","tags":[],"title":"DARM: Control-Flow Melding for SIMT Thread Divergence Reduction","type":"publication"},{"authors":["Yuyan Bao","Kirshanthan Sundararajah","Raghav Malik","Qianchuan Ye","Christopher Wagner","Nouraldin Jaber","Fei Wang","Mohammad Hassan Ameri","Donghang Lu","Alexander Seto","Benjamin Delaware","Roopsha Samanta","Aniket Kate","Christina Garman","Jeremiah Blocki","Pierre-David Letourneau","Benoit Meister","Jonathan Springer","Tiark Rompf","Milind Kulkarni"],"categories":null,"content":"","date":1633046400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633046400,"objectID":"0d7230e0e3133590de52b462f3c8b651","permalink":"https://kirshanthans.github.io/publication/2021gpce/","publishdate":"2021-10-01T00:00:00Z","relpermalink":"/publication/2021gpce/","section":"publication","summary":"Cryptographic techniques have the potential to enable distrusting parties to collaborate in fundamentally new ways, but their practical implementation poses numerous challenges. An important class of such cryptographic techniques is known as Secure Multi-Party Computation (MPC). Developing Secure MPC applications in realistic scenarios requires extensive knowledge spanning multiple areas of cryptography and systems. And while the steps to arrive at a solution for a particular application are often straightforward, it remains difficult to make the implementation efficient, and tedious to apply those same steps to a slightly different application from scratch. Hence, it is an important problem to design platforms for implementing Secure MPC applications with minimum effort and using techniques accessible to non-experts in cryptography. In this paper, we present the HACCLE (High Assurance Compositional Cryptography: Languages and Environments) toolchain, specifically targeted to MPC applications. HACCLE contains an embedded domain-specific language Harpoon, for software developers without cryptographic expertise to write MPC-based programs, and uses Lightweight Modular Staging (LMS) for code generation. Harpoon programs are compiled into acyclic circuits represented in HACCLE’s Intermediate Representation (HIR) that serves as an abstraction over different cryptographic protocols such as secret sharing, homomorphic encryption, or garbled circuits. Implementations of different cryptographic protocols serve as different backends of our toolchain. The extensible design of HIR allows cryptographic experts to plug in new primitives and protocols to realize computation. And the use of standard metaprogramming techniques lowers the development effort significantly. Harpoon programs are compiled into acyclic circuits represented in HACCLE’s Intermediate Representation (HIR) that serves as an abstraction over different cryptographic protocols such as secret sharing, homomorphic encryption, or garbled circuits. Implementations of different cryptographic protocols serve as different backends of our toolchain. The extensible design of HIR allows cryptographic experts to plug in new primitives and protocols to realize computation. And the use of standard metaprogramming techniques lowers the development effort significantly. We have implemented Harpoon and HACCLE, and used them to program interesting applications (e.g., secure auction) and key computation components of Secure MPC applications (e.g., matrix-vector multiplication and merge sort). We show that the performance is improved by using our optimization strategies and heuristics.","tags":[],"title":"HACCLE: Metaprogramming for Secure Multi-Party Computation","type":"publication"},{"authors":["Kirshanthan Sundararajah","Milind Kulkarni"],"categories":null,"content":"","date":1559952000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559952000,"objectID":"f29ec1f1c60c01d49332e7c7fc95138c","permalink":"https://kirshanthans.github.io/publication/2019pldia/","publishdate":"2019-06-08T00:00:00Z","relpermalink":"/publication/2019pldia/","section":"publication","summary":"Scheduling transformations reorder a program’s operations to improve locality and/or parallelism. The polyhedral model is a general framework for composing and applying instance-wise scheduling transformations for loop-based programs, but there is no analogous framework for recursive programs. This paper presents an approach for composing and applying scheduling transformations—like inlining, interchange, and code motion—to nested recursive programs. This paper describes the phases of the approach—representing dynamic instances, composing and applying transformations, reasoning about correctness—and shows that these techniques can verify the soundness of composed transformations.","tags":[],"title":"Composable, Sound Transformations of Nested Recursion and Loops","type":"publication"},{"authors":["Laith Sakka","Kirshanthan Sundararajah","Ryan R Newton","Milind Kulkarni"],"categories":null,"content":"","date":1559952000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559952000,"objectID":"fd100993a57595cfc3cb63f8db7fadb2","permalink":"https://kirshanthans.github.io/publication/2019pldib/","publishdate":"2019-06-08T00:00:00Z","relpermalink":"/publication/2019pldib/","section":"publication","summary":"Applications in many domains are based on a series of traversals of tree structures, and fusing these traversals together to reduce the total number of passes over the tree is a common, important optimization technique. In applications such as compilers and render trees, these trees are heterogeneous: different nodes of the tree have different types. Unfortunately, prior work for fusing traversals falls short in different ways: they do not handle heterogeneity; they require using domain-specific languages to express an application; they rely on the programmer to aver that fusing traversals is safe, without any soundness guarantee; or they can only perform coarse-grain fusion, leading to missed fusion opportunities. This paper addresses these shortcomings to build a framework for fusing traversals of heterogeneous trees that is automatic, sound, and fine-grained. We show across several case studies that our approach is able to allow programmers to write simple, intuitive traversals, and then automatically fuse them to substantially improve performance.","tags":[],"title":"Sound, Fine-grained Traversal Fusion for Heterogeneous Trees","type":"publication"},{"authors":["Nikhil Hegde","Jianqiao Liu","Kirshanthan Sundararajah","Milind Kulkarni"],"categories":null,"content":"","date":1507766400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1507766400,"objectID":"5e13d897f98b608de427a9583d62d356","permalink":"https://kirshanthans.github.io/publication/2017ispass/","publishdate":"2017-10-12T00:00:00Z","relpermalink":"/publication/2017ispass/","section":"publication","summary":"An interesting class of irregular algorithms is tree traversal algorithms, which repeatedly traverse various trees to perform efficient computations. Tree traversal algorithms form the algorithmic kernels in an important set of applications in scientific computing, computer graphics, bioinformatics, and data mining, etc. There has been increasing interest in understanding tree traversal algorithms, optimizing them, and applying them in a wide variety of settings. Crucially, while there are many possible optimizations for tree traversal algorithms, which optimizations apply to which algorithms is dependent on algorithmic characteristics. In this work, we present a suite of tree traversal kernels, drawn from diverse domains, called Treelogy, to explore the connection between tree traversal algorithms and state-of-the-art optimizations. We characterize these algorithms by developing an ontology based on their structural properties. The attributes extracted through our ontology, for a given traversal kernel, can aid in quick analysis of the suitability of platform- and application-specific as well as independent optimizations. We provide reference implementations of these kernels for three platforms: shared memory multicores, distributed memory systems, and GPUs, and evaluate their scalability.","tags":[],"title":"Treelogy: A Benchmark Suite for Tree Traversals","type":"publication"},{"authors":["Laith Sakka","Kirshanthan Sundararajah","Milind Kulkarni"],"categories":null,"content":"","date":1492992000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1492992000,"objectID":"255d7414526ff934b081dcc51d767b40","permalink":"https://kirshanthans.github.io/publication/2017oopsla/","publishdate":"2017-04-24T00:00:00Z","relpermalink":"/publication/2017oopsla/","section":"publication","summary":"Series of traversals of tree structures arise in numerous contexts: abstract syntax tree traversals in compiler passes, rendering traversals of the DOM in web browsers, kd-tree traversals in computational simulation codes. In each of these settings, a tree is traversed multiple times to compute various values and modify various portions of the tree. While it is relatively easy to write these traversals as separate small updates to the tree, for efficiency reasons, traversals are often manually fused to reduce the number of times that each portion of the tree is traversed: by performing multiple operations on the tree simultaneously, each node of the tree can be visited fewer times, increasing opportunities for optimization and decreasing cache pressure and other overheads. This fusion process is often done manually, requiring careful understanding of how each of traversals of the tree interact. This paper presents an automatic approach to traversal fusion: tree traversals can be written independently, and then our framework analyzes the dependences between the traversals to determine how they can be fused to reduce the number of visits to each node in the tree. A critical aspect of our framework is that it exploits two opportunities to increase the amount of fusion: i) it automatically integrates code motion, and ii) it supports partial fusion, where portions of one traversal can be fused with another, allowing for a reduction in node visits without requiring that two traversals be fully fused. We implement our framework in Clang, and show across several case studies that we can successfully fuse complex tree traversals, reducing the overall number of traversals and substantially improving locality and performance.","tags":[],"title":"TreeFuser: A Framework for Analyzing and Fusing General Recursive Tree Traversals","type":"publication"},{"authors":["Kirshanthan Sundararajah","Laith Sakka","Milind Kulkarni"],"categories":null,"content":"","date":1491264000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1491264000,"objectID":"0dabaddc7537379bd2cb4f27154a35eb","permalink":"https://kirshanthans.github.io/publication/2017asplos/","publishdate":"2017-04-04T00:00:00Z","relpermalink":"/publication/2017asplos/","section":"publication","summary":"There has been a significant amount of effort invested in designing scheduling transformations such as loop tiling and loop fusion that rearrange the execution of dynamic instances of loop nests to place operations that access the same data close together temporally. In recent years, there has been interest in designing similar transformations that operate on recursive programs, but until now these transformations have only considered simple scenarios: multiple recursions to be fused, or a recursion nested inside a simple loop. This paper develops the first set of scheduling transformations for nested recursions: recursive methods that call other recursive methods. These are the recursive analog to nested loops. We present a transformation called recursion twisting that automatically improves locality at all levels of the memory hierarchy, and show that this transformation can yield substantial performance improvements across several benchmarks that exhibit nested recursion.","tags":[],"title":"Locality Transformations for Nested Recursive Iteration Spaces","type":"publication"},{"authors":["Kirshanthan Sundararajah","Sanath Jayasena"],"categories":null,"content":"","date":1459468800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1459468800,"objectID":"1b2f5d117427cf9c558f3e8d7e988e09","permalink":"https://kirshanthans.github.io/publication/2016mercon/","publishdate":"2016-04-01T00:00:00Z","relpermalink":"/publication/2016mercon/","section":"publication","summary":"In a program, not all the bits of a variable are always used during execution. Identifying the minimum number of bits necessary to represent a variable in a program can potentially provide optimization opportunities. Providing the knowledge of bitwidths to a compilation and execution framework will be advantageous if it could use that information to optimize the execution of the program, for instance, being able to select instructions for SIMD vectorization. This paper introduces a framework to exploit the potential vectorizations hidden in a program which is not exposed during static compilation time. Our framework unlocks instruction level data parallelism by using the bitwidths of array like variables that depend on runtime input. Our framework shows a maximum achievable performance gain of 37% and a mean achievable performance gain of 11% against the ICC compiler on our micro benchmark suite.","tags":[],"title":"Model-based Input-adaptive Vectorization","type":"publication"},{"authors":["Kirshanthan Sundararajah","Lajanugen Logeswaran","Nisal Panagoda","Lakshitha Prabath Wijesinghe","Varuna De Silva","Ajith Pasqual"],"categories":null,"content":"","date":1417392000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1417392000,"objectID":"c667f15fbd86406328b5807db7d6e663","permalink":"https://kirshanthans.github.io/publication/2014isvc/","publishdate":"2014-12-01T00:00:00Z","relpermalink":"/publication/2014isvc/","section":"publication","summary":"Multi-view video has gained widespread popularity in the recent years. 3DTV, surveillance, immersive teleconferencing and free view-point television are few notable applications of multi-view video. Excessive storage and transmission bandwidth requirements are the major challenges faced by the industry in facilitating multi-view video applications. This paper presents efficient tools for coding of multi-view video based on the state of the art single view video coding standard H.265/HEVC (High Efficiency Video Coding). Our approach employs the LDI (Layered Depth Image) representation technique which is capable of compactly representing 3D scene content. We propose techniques and algorithms for LDI construction, view synthesis, efficient coding of LDI layers and associated auxiliary information. Subjective assessments indicate that our approach offers more than 50% reduction in bitrate compared to HEVC simulcast for the same subjective quality under practical operating bitrates.","tags":[],"title":"Layered Depth Image Based HEVC Multi-view Codec","type":"publication"}]